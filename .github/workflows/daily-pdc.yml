name: Daily PDC

on:
  workflow_dispatch:
  schedule:
    - cron: '0 3 * * *'
  repository_dispatch:
    types: [pdc-compose]

permissions:
  contents: write

env:
  LAB_REPO: balaji-kadri/lab-workflow
  LAB_WORKFLOW: build.yml

  SERVICE_REPO: balaji-kadri/service-workflow
  SERVICE_WORKFLOW: build.yml

  OS_REPO: balaji-kadri/os-workflow
  OS_WORKFLOW: build.yml

  PERF_BUDGET: "0.10"   # perf gate threshold

concurrency:
  group: daily-pdc-${{ github.ref }}
  cancel-in-progress: true

jobs:
  compose:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout PDC repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Prepare inputs
        run: mkdir -p inputs

      # LAB artifacts
      - name: Lab - download ALL artifacts
        uses: dawidd6/action-download-artifact@v2
        with:
          github_token: ${{ secrets.PDC_DISPATCH_TOKEN }}
          repo: ${{ env.LAB_REPO }}
          workflow: ${{ env.LAB_WORKFLOW }}
          path: inputs/lab_all

      - name: Lab - normalize
        run: |
          set -euo pipefail
          f="$(find inputs/lab_all -type f -name 'lab.json' | head -n1 || true)"
          if [ -z "$f" ]; then echo "❌ lab.json not found"; exit 2; fi
          cp "$f" inputs/lab.json

      # SERVICE artifacts
      - name: Service - download ALL artifacts
        uses: dawidd6/action-download-artifact@v2
        with:
          github_token: ${{ secrets.PDC_DISPATCH_TOKEN }}
          repo: ${{ env.SERVICE_REPO }}
          workflow: ${{ env.SERVICE_WORKFLOW }}
          path: inputs/service_all

      - name: Service - normalize
        run: |
          set -euo pipefail
          f="$(find inputs/service_all -type f -name 'service.json' | head -n1 || true)"
          if [ -z "$f" ]; then echo "❌ service.json not found"; exit 2; fi
          cp "$f" inputs/service.json

      # OS artifacts
      - name: OS - download ALL artifacts
        uses: dawidd6/action-download-artifact@v2
        with:
          github_token: ${{ secrets.PDC_DISPATCH_TOKEN }}
          repo: ${{ env.OS_REPO }}
          workflow: ${{ env.OS_WORKFLOW }}
          path: inputs/os_all

      - name: OS - normalize
        run: |
          set -euo pipefail
          f="$(find inputs/os_all -type f -name 'os.json' | head -n1 || true)"
          if [ -z "$f" ]; then echo "❌ os.json not found"; exit 2; fi
          cp "$f" inputs/os.json

      - name: Verify inputs
        run: |
          echo "Inputs:"; ls -la inputs
          test -f inputs/lab.json && test -f inputs/service.json && test -f inputs/os.json

      - name: Compose PDC
        run: |
          python3 scripts/compose_pdc.py \
            --lab inputs/lab.json \
            --service inputs/service.json \
            --os inputs/os.json

      - name: Upload composed artifact
        uses: actions/upload-artifact@v4
        with:
          name: pdc-composed
          path: dist/pdc.json

  test_and_gate:
    runs-on: ubuntu-latest
    needs: compose
    steps:
      - name: Checkout PDC repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Generate test reports
        run: |
          python3 scripts/run_e2e.py --report reports/e2e.json
          python3 scripts/run_perf.py --budget "${{ env.PERF_BUDGET }}" --report reports/perf.json
          python3 scripts/run_security.py --report reports/security.json
          python3 scripts/run_coverage.py --report reports/coverage.json

      - name: Verify reports
        run: |
          ls -la reports || { echo "reports missing"; exit 1; }
          for f in coverage.json e2e.json perf.json security.json; do
            [ -f "reports/$f" ] || { echo "❌ Missing reports/$f"; exit 2; }
          done

      - name: Gate on results
        run: |
          python3 scripts/gate.py \
            --coverage reports/coverage.json \
            --e2e reports/e2e.json \
            --perf reports/perf.json \
            --security reports/security.json \
            --policy policies/pdc_policy.json

      - name: Upload test reports
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: pdc-test-reports
          path: reports

  release:
    runs-on: ubuntu-latest
    needs: test_and_gate
    if: ${{ needs.test_and_gate.result == 'success' }}
    steps:
      - name: Checkout PDC repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download test reports
        uses: actions/download-artifact@v4
        with:
          name: pdc-test-reports
          path: reports

      - name: Configure Git (tagging)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Tag Release
        run: |
          TAG="pdc-$(date +'%Y.%m.%d')-build${{ github.run_number }}"
          echo "TAG=$TAG" >> $GITHUB_ENV
          git tag -a "$TAG" -m "Daily PDC release"
          git push origin "$TAG"

      - name: Emit dashboard payload
        run: |
          python3 scripts/emit_dashboard.py \
            --tag "$TAG" \
            --commit "${{ github.sha }}" \
            --reports reports \
            --out dashboard/payload.json

      - name: Upload dashboard payload
        uses: actions/upload-artifact@v4
        with:
          name: pdc-dashboard-payload
          path: dashboard/payload.json

      # ---------- GitHub Pages publish ----------
      - name: Prepare dashboard workspace
        run: |
          rm -rf dashboard-work && mkdir -p dashboard-work
          cp -r dashboard-site-src/* dashboard-work/ || true
          cp dashboard/payload.json dashboard-work/payload.json

      # ✅ Ensure index.html exists to avoid 404
      - name: Ensure index.html exists
        run: |
          if [ ! -f "dashboard-work/index.html" ]; then
            echo "⚠️ index.html missing, creating a placeholder"
            echo "<!DOCTYPE html><html><head><title>PDC Dashboard</title></head><body><h1>PDC Dashboard</h1><p>Payload: $(date)</p></body></html>" > dashboard-work/index.html
          fi

      - name: Bring in existing history (if any)
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: _ghpages

      - name: Merge history.json
        run: |
          python3 - << 'PY'
          import json, pathlib, time
          site = pathlib.Path('dashboard-work')
          ghp  = pathlib.Path('_ghpages')

          payload = json.loads((site/'payload.json').read_text(encoding='utf-8'))
          payload['timestamp'] = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())

          hist = []
          src = ghp/'history.json'
          if src.exists():
            try:
              hist = json.loads(src.read_text(encoding='utf-8'))
              if not isinstance(hist, list): hist = []
            except Exception:
              hist = []

          tag = payload.get('build', {}).get('tag')
          hist = [e for e in hist if e.get('build', {}).get('tag') != tag]
          hist.append(payload)
          hist = sorted(hist, key=lambda e: e.get('timestamp',''), reverse=True)[:200]

          (site/'history.json').write_text(json.dumps(hist, indent=2), encoding='utf-8')
          PY

      - name: Deploy dashboard to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: dashboard-work
          publish_branch: gh-pages
          keep_files: true
          commit_message: "Dashboard update: ${{ env.TAG }}"
